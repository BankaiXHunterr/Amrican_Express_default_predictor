{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install xgboost==1.2.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oBazbqb-AFjt",
        "outputId": "31f27a91-3fe2-4799-ddbe-c703eee56ef3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting xgboost==1.2.0\n",
            "  Downloading xgboost-1.2.0-py3-none-manylinux2010_x86_64.whl (148.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 148.9 MB 40 kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from xgboost==1.2.0) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from xgboost==1.2.0) (1.7.3)\n",
            "Installing collected packages: xgboost\n",
            "  Attempting uninstall: xgboost\n",
            "    Found existing installation: xgboost 0.90\n",
            "    Uninstalling xgboost-0.90:\n",
            "      Successfully uninstalled xgboost-0.90\n",
            "Successfully installed xgboost-1.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "3tyRIlmORnCe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c78f963-513e-4a7d-b1f3-47dcf79910f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: invalid option -- 'q'\n",
            "Try 'rm --help' for more information.\n",
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "if not os.path.exists('/content/train_data.ftr'):\n",
        "  \n",
        "  !pip install kaggle -q\n",
        "  !mkdir ~/.kaggle \n",
        "  !cp kaggle.json ~/.kaggle/\n",
        "\n",
        "  !rm /content/sample_data -r -q\n",
        "  # !kaggle datasets download -d raddar/amex-data-integer-dtypes-parquet-format\n",
        "  !kaggle datasets download -d munumbutt/amexfeather -q\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from zipfile import ZipFile\n",
        "import os\n",
        "\n",
        "if not os.path.exists('/content/train_data.ftr'):\n",
        "\n",
        "  with ZipFile('/content/amexfeather.zip', 'r') as zipObj:\n",
        "      listOfFileNames = zipObj.namelist()\n",
        "\n",
        "      # list_ext = ['train_data.ftr','test_data.ftr']\n",
        "      list_ext = ['train_data.ftr']\n",
        "\n",
        "\n",
        "      for f_name in listOfFileNames:\n",
        "          if f_name in list_ext:\n",
        "            zipObj.extract(f_name)\n",
        "\n"
      ],
      "metadata": {
        "id": "zKHl8RazRxXL"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import rapid\n",
        "import cupy\n",
        "import datetime\n",
        "import re\n",
        "import tensorflow as tf\n",
        "# import tensorflow_addons as tfa\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from keras.layers import Embedding\n",
        "from tensorflow.keras.layers import Input,Activation,Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import concatenate,Conv1D,MaxPool1D,Input,Flatten,Dropout,Normalization\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "from tensorflow.keras.layers import Embedding\n",
        "# from tf.keras.preprocessing.text import Tokeni\n",
        "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
        "import pickle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "from tensorflow.keras.callbacks import EarlyStopping,ModelCheckpoint,\\\n",
        "LearningRateScheduler, TerminateOnNaN\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import datetime\n",
        "from time import time\n",
        "from zipfile import ZipFile\n",
        "import tqdm\n",
        "import pickle\n",
        "\n",
        "import pickle\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_selection import SelectKBest, chi2, f_regression\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "import matplotlib\n",
        "matplotlib.use(u'nbAgg')\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import pickle\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn import preprocessing\n",
        "import pandas as pd\n",
        "from multiprocessing import Process\n",
        "import multiprocessing\n",
        "import codecs\n",
        "import random as r\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import log_loss\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import re\n",
        "from nltk.util import ngrams\n",
        "from sklearn.feature_selection import SelectKBest, chi2, f_regression\n",
        "\n",
        "import scipy.sparse\n",
        "import gc\n",
        "import pickle as pkl\n",
        "from datetime import datetime as dt\n",
        "%matplotlib inline\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras.callbacks import EarlyStopping,ModelCheckpoint,\\\n",
        "LearningRateScheduler, TerminateOnNaN\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "import pickle\n",
        "import numpy as np\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "from sklearn import set_config\n",
        "set_config(display='diagram')"
      ],
      "metadata": {
        "id": "18nEtEfiRzba"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LvVE73KtSDFp",
        "outputId": "9765f94b-a831-4060-b046-fd6afc7dcf06"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !rm /content/data/ -r\n",
        "# !rm /content/processors -r\n",
        "# !rm /content/model_para -r"
      ],
      "metadata": {
        "id": "OWC0jcpWSLCp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.exists('/content/data/train/x_train/'):\n",
        "    \n",
        "    os.makedirs('/content/data/train/x_train/')\n",
        "    os.makedirs('/content/data/train/y_train/')\n",
        "\n",
        "    os.makedirs('/content/data/val/x_val/')\n",
        "    os.makedirs('/content/data/val/y_val/')\n",
        "\n",
        "    os.makedirs('/content/processors/')\n",
        "    os.makedirs('/content/model_para/')\n",
        "\n",
        "\n",
        "if not os.path.exists('/content/drive/MyDrive/Applied_AI/casestudy/model_para'):\n",
        "  os.makedirs('/content/drive/MyDrive/Applied_AI/casestudy/model_para')\n",
        "  os.makedirs('/content/drive/MyDrive/Applied_AI/casestudy/model_para/model/xgb')\n",
        "  os.makedirs('/content/drive/MyDrive/Applied_AI/casestudy/model_para/model/txt')\n",
        "  os.makedirs('/content/drive/MyDrive/Applied_AI/casestudy/model_para/model/json')\n",
        "\n",
        "\n",
        "drive_path = '/content/drive/MyDrive/Applied_AI/casestudy/model_para'"
      ],
      "metadata": {
        "id": "bMz-uYTeSFLp"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Splitting Data into train"
      ],
      "metadata": {
        "id": "LXIfbVvcSMFz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "target = pd.read_csv('/content/train_labels.csv')\n",
        "train,test = train_test_split(target,test_size=0.2,stratify=target['target'],random_state=33)\n",
        "\n",
        "train_index, test_index= train['customer_ID'].values,test['customer_ID'].values\n",
        "\n",
        "del train,test"
      ],
      "metadata": {
        "id": "3mxLBRECSN05"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Feature Engiering Function"
      ],
      "metadata": {
        "id": "586SeY7KaIzE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "input: df (dataframe)\n",
        "\n",
        "  num_feature: all the numerical columns\n",
        "\n",
        "  doing groupby operation based on customer_ID & the applying different\n",
        "  aggregation operation like : mean, std, min, max, last.\n",
        "\n",
        "  we will save each column with datatype = float16 \n",
        "  to save space memory as data is very large\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "def numerical_featute(df):\n",
        "    all_cols = [c for c in list(df.columns) if c not in ['customer_ID','S_2']]\n",
        "    cat_features = [\"B_30\",\"B_38\",\"D_114\",\"D_116\",\"D_117\",\"D_120\",\"D_126\",\"D_63\",\"D_64\",\"D_66\",\"D_68\"]\n",
        "    num_features = [col for col in all_cols if col not in cat_features]\n",
        "\n",
        "\n",
        "    new_df = df.groupby(\"customer_ID\")[num_features].agg(['mean', 'std', 'min', 'max', 'last'])\n",
        "    new_df.columns = ['_'.join(x) for x in new_df.columns]\n",
        "\n",
        "    for col in list(new_df.columns):\n",
        "      new_df[col] = new_df[col].astype('float16')\n",
        "    \n",
        "    column_name = list(new_df.columns)\n",
        "\n",
        "    return new_df"
      ],
      "metadata": {
        "id": "TFGv-GfdSPHZ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "input: df (dataframe)\n",
        "\n",
        "  steps:\n",
        "    \n",
        "    1. getting all the categorical columns\n",
        "    2. creating off set to handle np.nan , we will set np.nan as 1.\n",
        "    3. column D_63, D_64 are string type categorical columns with '' as one class & -1 as another class\n",
        "        we will replace '' with X & -1 with Y.\n",
        "    4. getting the total number of statemns each unique customer had & storing it in a df_count.\n",
        "    5. out of 11 categorical column 9 are numerical / label encoded hence we will use it label encoded\n",
        "        with adding the offset value to handle the np.nan as 1.\n",
        "    \n",
        "    \n",
        "    6. if train == True:\n",
        "        we will use the sklearns OneHotEncoder to encode the categorical columns & the saving\n",
        "        it as pkl file to transform the data without needing to fit it again.\n",
        "    7. if train == False:\n",
        "        we will transform the data directly.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "def categorical_featute_engg(df,train=False):\n",
        "\n",
        "  # defining all the faetures\n",
        "\n",
        "    one_hot_feature = ['D_63','D_64']\n",
        "    cat = [\"B_30\",\"B_38\",\"D_114\",\"D_116\",\"D_117\",\"D_120\",\"D_126\",\"D_66\",\"D_68\"]\n",
        "    offset = [2,1,2,2,3,2,3,2,2]  #2 minus minimal value in full train csv\n",
        "\n",
        "    # Making categoriacl data drame with only categorical features\n",
        "    df_cat = df[['customer_ID']+cat+one_hot_feature]\n",
        "\n",
        "    df_cat[one_hot_feature] = df_cat[one_hot_feature].replace(r'', 'X', regex=True)\n",
        "    df_cat[one_hot_feature] = df_cat[one_hot_feature].replace(r'-1', 'Y', regex=True)\n",
        "    \n",
        "    df_count = df.groupby('customer_ID')['S_2'].agg(['count'])\n",
        "    df_count.columns = ['count']\n",
        "\n",
        "    del df\n",
        "\n",
        "\n",
        "    for col,s in zip(cat,offset):\n",
        "\n",
        "      df_cat[col] = np.array(df_cat[col].values) + s\n",
        "      df_cat[col] = df_cat[col].fillna(1).astype('int8')\n",
        "\n",
        "    df_cat = df_cat.reset_index(drop=True)\n",
        "\n",
        "\n",
        "    if train:\n",
        "\n",
        "      if not os.path.exists('/content/model_para/one_hot_encoder_D_63_D_64.pkl'):\n",
        "\n",
        "        pipe_one_hot_encoder = Pipeline(steps=[('one_hot_encoder',OneHotEncoder(handle_unknown='ignore'))])\n",
        "\n",
        "        pipe_one_hot_encoder.fit(df_cat[one_hot_feature])\n",
        "\n",
        "        pickle.dump(pipe_one_hot_encoder,open('/content/model_para/one_hot_encoder_D_63_D_64.pkl','wb'))\n",
        "        pickle.dump(pipe_one_hot_encoder,open(drive_path + '/one_hot_encoder_D_63_D_64.pkl','wb'))\n",
        "\n",
        "        # getting One Hot Encoded Feature Name\n",
        "        one_hot_ = [[x[0]+'_'+y for y in list(x[1])] for x in zip(['D_63','D_64'],pipe_one_hot_encoder['one_hot_encoder'].categories_)]\n",
        "        one_hot_ = one_hot_[0] + one_hot_[1]\n",
        "        \n",
        "        pickle.dump(one_hot_,open('/content/model_para/one_hot_encoder_D_63_D_64.pkl_feature_names','wb'))\n",
        "        pickle.dump(one_hot_,open(drive_path + '/one_hot_encoder_D_63_D_64.pkl_feature_names','wb'))\n",
        "\n",
        "        one_hot_df = pd.DataFrame(pipe_one_hot_encoder.transform(df_cat[one_hot_feature]).toarray().astype('int8'),columns=one_hot_)\n",
        "\n",
        "      else:\n",
        "\n",
        "        pipe_one_hot_encoder = pickle.load(open('/content/model_para/one_hot_encoder_D_63_D_64.pkl','rb'))\n",
        "        one_hot_ =  pickle.load(open('/content/model_para/one_hot_encoder_D_63_D_64.pkl_feature_names','rb'))\n",
        "        \n",
        "        one_hot_df = pd.DataFrame(pipe_one_hot_encoder.transform(df_cat[one_hot_feature]).toarray().astype('int8'),columns=one_hot_)\n",
        "\n",
        "      df_cat = df_cat.drop(['D_63','D_64'],axis=1)\n",
        "      df_cat = pd.concat([df_cat,one_hot_df],axis=1)\n",
        "\n",
        "      del one_hot_df\n",
        "\n",
        "\n",
        "\n",
        "      df_cat = df_cat.groupby('customer_ID')[list(df_cat.columns)[1:]].agg(['first','last', 'nunique'])\n",
        "      df_cat.columns = ['_'.join(x) for x in df_cat.columns]\n",
        "\n",
        "      df_cat['customer_ID'] = df_cat.index\n",
        "      df_cat = df_cat[['customer_ID']+list(df_cat.columns)[:-1]]\n",
        "      df_cat = df_cat.reset_index(drop=True)\n",
        "\n",
        "      for col in df_cat.columns[1:]:\n",
        "        df_cat[col] = df_cat[col].astype('int8')\n",
        "\n",
        "\n",
        "      df_cat = df_cat.merge(df_count,on='customer_ID')\n",
        "      del df_count\n",
        "\n",
        "      return df_cat\n",
        "\n",
        "\n",
        "    else:\n",
        "  \n",
        "      pipe_one_hot_encoder = pickle.load(open('/content/model_para/one_hot_encoder_D_63_D_64.pkl','rb'))\n",
        "      one_hot_ =  pickle.load(open('/content/model_para/one_hot_encoder_D_63_D_64.pkl_feature_names','rb'))\n",
        "      \n",
        "      one_hot_df = pd.DataFrame(pipe_one_hot_encoder.transform(df_cat[one_hot_feature]).toarray().astype('int8'),columns=one_hot_)\n",
        "      \n",
        "\n",
        "      df_cat = df_cat.drop(['D_63','D_64'],axis=1)\n",
        "      df_cat = pd.concat([df_cat,one_hot_df],axis=1)\n",
        "\n",
        "      del one_hot_df\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "      df_cat = df_cat.groupby('customer_ID')[list(df_cat.columns)[1:]].agg(['first','last', 'nunique'])\n",
        "      df_cat.columns = ['_'.join(x) for x in df_cat.columns]\n",
        "\n",
        "      df_cat['customer_ID'] = df_cat.index\n",
        "\n",
        "      df_cat = df_cat[['customer_ID']+list(df_cat.columns)[:-1]]\n",
        "      df_cat = df_cat.reset_index(drop=True)\n",
        "\n",
        "      for col in df_cat.columns[1:]:\n",
        "        df_cat[col] = df_cat[col].astype('int8')\n",
        "\n",
        "\n",
        "      df_cat = df_cat.merge(df_count,on='customer_ID')\n",
        "      del df_count\n",
        "\n",
        "      return df_cat\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "LEToZJeQTuTY"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Fitting Data"
      ],
      "metadata": {
        "id": "7bg-FoqDaMwd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if not (os.path.exists('/content/data/train/x_train/cat.ftr') and os.path.exists('/content/data/val/x_val/cat.ftr')):\n",
        "\n",
        "  df = pd.read_feather('/content/train_data.ftr')\n",
        "\n",
        "  train_df = df[df['customer_ID'].isin(train_index)]\n",
        "  train_cat_df = categorical_featute_engg(train_df,train=True)\n",
        "\n",
        "  del train_df\n",
        "\n",
        "  test_df = df[df['customer_ID'].isin(test_index)]\n",
        "  test_cat_df = categorical_featute_engg(test_df)\n",
        "\n",
        "  del test_df\n",
        "\n",
        "  if not os.path.exists('/content/data/train/x_train/cat.ftr'):\n",
        "    train_cat_df.to_feather('/content/data/train/x_train/cat.ftr')\n",
        "    test_cat_df.to_feather('/content/data/val/x_val/cat.ftr')\n",
        "    \n",
        "  del train_cat_df, test_cat_df, df"
      ],
      "metadata": {
        "id": "n0pJc9uVZRjG"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.exists('/content/data/train/x_train/num_df.ftr'):\n",
        "\n",
        "  df = pd.read_feather('/content/train_data.ftr')\n",
        "  df = df.drop(['target'],axis=1)\n",
        "  # Feature_engg For Numerical features\n",
        "\n",
        "  if not os.path.exists('/content/data/train/x_train/num_df.ftr'):\n",
        "\n",
        "    num_df = numerical_featute(df[df['customer_ID'].isin(train_index)])\n",
        "    num_df = num_df.reset_index()\n",
        "    num_df = num_df.replace(np.inf,np.nan)\n",
        "    num_df = num_df.merge(target,on='customer_ID')\n",
        "\n",
        "    tar = num_df[['customer_ID','target']]\n",
        "    num_df = num_df.drop(['target'],axis=1)\n",
        "\n",
        "    num_df.to_feather('/content/data/train/x_train/num_df.ftr')\n",
        "    tar.to_feather('/content/data/train/y_train/target.ftr')\n",
        "    # pickle.dump(tar,open('/content/data/train/y_train/target.pkl','wb'))\n",
        "\n",
        "    del num_df\n",
        "\n",
        "  if not os.path.exists('/content/data/val/x_val/num_df.ftr'):\n",
        "\n",
        "    num_df = numerical_featute(df[df['customer_ID'].isin(test_index)])\n",
        "    num_df = num_df.reset_index()\n",
        "    num_df = num_df.replace(np.inf,np.nan)\n",
        "    num_df = num_df.merge(target,on='customer_ID')\n",
        "\n",
        "\n",
        "    tar = num_df[['customer_ID','target']]\n",
        "    num_df = num_df.drop(['target'],axis=1)\n",
        "\n",
        "    num_df.to_feather('/content/data/val/x_val/num_df.ftr')\n",
        "    # pickle.dump(tar,open('/content/data/val/y_val/target.pkl','wb'))\n",
        "    tar.to_feather('/content/data/val/y_val/target.ftr')\n",
        "\n",
        "\n",
        "    del num_df, df\n"
      ],
      "metadata": {
        "id": "4K6QPvc0bebH"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature Standardization"
      ],
      "metadata": {
        "id": "BOoLlpNUjyB_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.exists('/content/processors/numerical_data_preprocessing_pipeline.pkl'):\n",
        "\n",
        "  num_df = pd.read_feather('/content/data/train/x_train/num_df.ftr')\n",
        "\n",
        "  pipe_num = Pipeline(steps=[\n",
        "        ('imputer',SimpleImputer(missing_values=np.nan,strategy='median')),\n",
        "        ('scalar', StandardScaler())\n",
        "    ])\n",
        "\n",
        "  pipe_num.fit(num_df.iloc[:,1:])\n",
        "\n",
        "  pickle.dump(pipe_num,open('/content/processors/numerical_data_preprocessing_pipeline.pkl','wb'))\n",
        "  pickle.dump(pipe_num,open(drive_path + '/numerical_data_preprocessing_pipeline.pkl','wb'))\n",
        "\n"
      ],
      "metadata": {
        "id": "gpmHve6Hd0Ci"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.exists('/content/processors/categorical_data_preprocessing_pipeline.pkl'):\n",
        "\n",
        "  cat_df = pd.read_feather('/content/data/train/x_train/cat.ftr')\n",
        "\n",
        "  # columns to standardize\n",
        "  cat_colum_std = [x for x in list(cat_df.columns)[1:-1] if x.split('_')[-1]=='nunique']+['count']\n",
        "\n",
        "  # columns not be standardize\n",
        "  cat_colum_not_std = [x for x in list(cat_df.columns) if x not in [x for x in list(cat_df.columns)[1:-1] if x.split('_')[-1]=='nunique']+['count']]\n",
        "\n",
        "    \n",
        "  pipe_cat = Pipeline(steps=[\n",
        "  ('scalar', StandardScaler())\n",
        "  ])\n",
        "\n",
        "  pipe_cat.fit(cat_df[cat_colum_std])\n",
        "  pickle.dump(pipe_cat,open('/content/processors/categorical_data_preprocessing_pipeline.pkl','wb'))\n",
        "  pickle.dump(pipe_cat,open(drive_path +'/categorical_data_preprocessing_pipeline.pkl','wb'))\n",
        "\n"
      ],
      "metadata": {
        "id": "1zRaGP0gkM3O"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transforming Data into Pipeline\n"
      ],
      "metadata": {
        "id": "o4_f1SmJkzHw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cat_df = pd.read_feather(f'/content/data/train/x_train/cat.ftr')\n",
        "# getting all the categoraical columns to standardize\n",
        "cat_colum_std = [x for x in list(cat_df.columns)[1:-1] if x.split('_')[-1]=='nunique']+['count']\n",
        "\n",
        "# getting all the categorical columns not to be standardized\n",
        "cat_colum_not_std = [x for x in list(cat_df.columns) if x not in cat_colum_std ]\n"
      ],
      "metadata": {
        "id": "pOfyQhA_Rewi"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def data_std(path):\n",
        "\n",
        "  feature_name = []\n",
        "  # reading the data\n",
        "  num_df = pd.read_feather(f'/content/data/{path}/x_{path}/num_df.ftr')\n",
        "  cat_df = pd.read_feather(f'/content/data/{path}/x_{path}/cat.ftr')\n",
        "  customer_ID = cat_df['customer_ID']\n",
        "\n",
        "  # getting all the categoraical columns to standardize\n",
        "  cat_colum_std = [x for x in list(cat_df.columns)[1:-1] if x.split('_')[-1]=='nunique']+['count']\n",
        "\n",
        "  # getting all the categorical columns not to be standardized\n",
        "  cat_colum_not_std = [x for x in list(cat_df.columns) if x not in cat_colum_std ]\n",
        "\n",
        "  pickle.dump(cat_colum_std,open(drive_path+'/cat_col_std.pkl','wb'))\n",
        "  pickle.dump(cat_colum_not_std,open(drive_path+'/cat_colum_not_std.pkl','wb'))\n",
        "\n",
        "  # getting data standardization pipeline\n",
        "\n",
        "  pipe_num = pickle.load(open('/content/processors/numerical_data_preprocessing_pipeline.pkl','rb'))\n",
        "  pipe_cat = pickle.load(open('/content/processors/categorical_data_preprocessing_pipeline.pkl','rb'))\n",
        "\n",
        "  feature_name += list(num_df.columns)[1:]\n",
        "  train_num = pipe_num.transform(num_df.iloc[:,1:])\n",
        "  \n",
        "  # # saving target of each datapoint \n",
        "  # target = num_df['target'].values.reshape(-1,1)\n",
        "  # pickle.dump(target,open(f'/content/data/{path}/y_{path}/{path}.pkl','wb'))\n",
        "\n",
        "\n",
        "  del num_df\n",
        "\n",
        "  feature_name += cat_colum_std\n",
        "  train_cat_std = pipe_cat.transform(cat_df[cat_colum_std])\n",
        "\n",
        "  feature_name += cat_colum_not_std[1:]\n",
        "  train_cat_non_std = np.array(cat_df[cat_colum_not_std[1:]])\n",
        "\n",
        "  del cat_df\n",
        "\n",
        "  final_data = np.concatenate([train_num,train_cat_std,train_cat_non_std],axis=1)\n",
        "  cupy.save(f'/content/data/{path}/x_{path}/{path}',final_data.astype('float16'))\n",
        "\n",
        "  pickle.dump(feature_name,open('/content/processors/feature_name.pkl','wb'))\n",
        "  pickle.dump(feature_name,open(drive_path + '/feature_name.pkl','wb'))\n",
        "\n",
        "  del final_data\n",
        "\n",
        "\n",
        "if not (os.path.exists('/content/data/train/x_train/train.npy') and \\\n",
        "        os.path.exists('/content/data/val/x_val/val.npy')):\n",
        "\n",
        "  data_std('train')\n",
        "  data_std('val')"
      ],
      "metadata": {
        "id": "iGulg_gokwRt"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Fitting Model"
      ],
      "metadata": {
        "id": "nE3iNMkvm00x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def amex_metric(y_true: pd.DataFrame, y_pred: pd.DataFrame) -> float:\n",
        "\n",
        "    def top_four_percent_captured(y_true: pd.DataFrame, y_pred: pd.DataFrame) -> float:\n",
        "        df = (pd.concat([y_true, y_pred], axis='columns')\n",
        "              .sort_values('prediction', ascending=False))\n",
        "        df['weight'] = df['target'].apply(lambda x: 20 if x==0 else 1)\n",
        "        four_pct_cutoff = int(0.04 * df['weight'].sum())\n",
        "        df['weight_cumsum'] = df['weight'].cumsum()\n",
        "        df_cutoff = df.loc[df['weight_cumsum'] <= four_pct_cutoff]\n",
        "        return (df_cutoff['target'] == 1).sum() / (df['target'] == 1).sum()\n",
        "        \n",
        "    def weighted_gini(y_true: pd.DataFrame, y_pred: pd.DataFrame) -> float:\n",
        "        df = (pd.concat([y_true, y_pred], axis='columns')\n",
        "              .sort_values('prediction', ascending=False))\n",
        "        df['weight'] = df['target'].apply(lambda x: 20 if x==0 else 1)\n",
        "        df['random'] = (df['weight'] / df['weight'].sum()).cumsum()\n",
        "        total_pos = (df['target'] * df['weight']).sum()\n",
        "        df['cum_pos_found'] = (df['target'] * df['weight']).cumsum()\n",
        "        df['lorentz'] = df['cum_pos_found'] / total_pos\n",
        "        df['gini'] = (df['lorentz'] - df['random']) * df['weight']\n",
        "        return df['gini'].sum()\n",
        "\n",
        "    def normalized_weighted_gini(y_true: pd.DataFrame, y_pred: pd.DataFrame) -> float:\n",
        "        y_true_pred = y_true.rename(columns={'target': 'prediction'})\n",
        "        return weighted_gini(y_true, y_pred) / weighted_gini(y_true, y_true_pred)\n",
        "\n",
        "    g = normalized_weighted_gini(y_true, y_pred)\n",
        "    d = top_four_percent_captured(y_true, y_pred)\n",
        "\n",
        "    return 0.5 * (g + d)\n",
        "\n",
        "def score(true,pred):\n",
        "\n",
        "  pred = pd.DataFrame(pred,columns=['prediction'])\n",
        "  true = pd.DataFrame(true,columns=['target'])\n",
        "  amx_score = amex_metric(true,pred)\n",
        "  return amx_score\n"
      ],
      "metadata": {
        "id": "PC_xy2rkm3rP"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "\n",
        "def load_data(path):\n",
        "  X = np.load(f'/content/data/{path}/x_{path}/{path}.npy')\n",
        "  # Y = pickle.load(open(f'/content/data/{path}/y_{path}/target.pkl','rb'))\n",
        "  Y = pd.read_feather(f'/content/data/{path}/y_{path}/target.ftr')\n",
        "\n",
        "\n",
        "  return X,Y\n",
        "\n",
        "X_train,Y_train = load_data('train')\n",
        "# X_val,Y_val = load_data('val')\n",
        "\n"
      ],
      "metadata": {
        "id": "0RmZhVeRmRa7"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hyper Parameter tuning & Model fitting"
      ],
      "metadata": {
        "id": "vUoBr-FkdRDq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import roc_auc_score, roc_curve\n",
        "\n",
        "def k_fold_index(X,Y):\n",
        "\n",
        "  cv_index = []\n",
        "  train_index = []\n",
        "  len_data = X.shape[0]\n",
        "  # getting optimal k_value for the training data set\n",
        "  k =  [x for x in range(4,20) if len_data%x == 0][0]\n",
        "  cross_validator = StratifiedKFold(n_splits=k,random_state=33,shuffle=True)\n",
        "\n",
        "  indexs = cross_validator.split(X=X, y=Y['target'].values)\n",
        "\n",
        "  for i in indexs:\n",
        "    train_index.append(i[0])\n",
        "    cv_index.append(i[1])\n",
        "\n",
        "  return train_index, cv_index, k"
      ],
      "metadata": {
        "id": "2vML5n1YdQKa"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Auc_score(X_train, y_train, max_tree_depth,number_of_estimators):\n",
        "\n",
        "  AUC_SCORE = {}\n",
        "  auc_pretty_table = []\n",
        "  train_index ,cv_index, k_val = k_fold_index(X_train,y_train)\n",
        "\n",
        "  l = ['n_estimetors','max_depth','train_AUC','val_AUC','AMX_train_score','AMX_val_score']\n",
        "  ','.join(l)\n",
        "\n",
        "  with open(drive_path+'/Auc_hyperpara_df.csv','w+') as f:\n",
        "    f.write(','.join(l))\n",
        "    f.write('\\n')\n",
        "\n",
        "    for i in tqdm(number_of_estimators):\n",
        "      for j in tqdm(max_tree_depth):\n",
        "        clf = XGBClassifier(tree_method='gpu_hist',\n",
        "                            max_depth=j,\n",
        "                            n_estimators=i,\n",
        "                            n_jobs=-1,\n",
        "                            single_precision_histogram=True)\n",
        "        AUC_cv = 0\n",
        "        AUC_train = 0\n",
        "        for k in (range(k_val)):\n",
        "\n",
        "\n",
        "          # Fitting the GBDT classifier algorithem & getting the probability score for Train\n",
        "          #  & Cross Validation set     \n",
        "      \n",
        "          clf.fit(X_train[train_index[k]],Y_train['target'].iloc[train_index[k]].values.reshape(-1,1))\n",
        "          y_cv_pred = clf.predict_proba(X_train[cv_index[k]] )\n",
        "          y_train_pred = clf.predict_proba(X_train[train_index[k]])\n",
        "\n",
        "          score_train = score(Y_train['target'].iloc[train_index[k]].values.reshape(-1,1),y_train_pred[:,1])\n",
        "          score_val = score(Y_train['target'].iloc[cv_index[k]].values.reshape(-1,1),y_cv_pred[:,1])\n",
        "\n",
        "          AUC_cv += roc_auc_score(Y_train['target'].iloc[cv_index[k]].values.reshape(-1,1),y_cv_pred[:,1])\n",
        "          AUC_train += roc_auc_score(Y_train['target'].iloc[train_index[k]].values.reshape(-1,1),y_train_pred[:,1])\n",
        "\n",
        "          _ = gc.collect()\n",
        "\n",
        "          # #calculating the avarage AUC score for the HyperParameter\n",
        "        AUC_SCORE[(i,j)] = [AUC_cv/k_val,AUC_train/k_val]     \n",
        "        auc_pretty_table.append((i,j,AUC_cv/k_val,AUC_train/k_val,score_train,score_val))\n",
        "\n",
        "        f.write(','.join(map(str,[i,j,AUC_cv/k_val,AUC_train/k_val,score_train,score_val])))\n",
        "        f.write('\\n')\n",
        "\n",
        "  return AUC_SCORE,auc_pretty_table"
      ],
      "metadata": {
        "id": "6Dhs1FR-dQCs"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# defining funcyion for creating table of result for diffrent\n",
        "# Number of estimetor\n",
        "# max depth,\n",
        "# CV_AUC score \n",
        "# Train_AUC score\n",
        "from prettytable import PrettyTable\n",
        "\n",
        "def pretty_table_creator(column_name_array,value_column_data):\n",
        "  y = PrettyTable()\n",
        "  y.field_names = column_name_array\n",
        "  for i in range(len(value_column_data)):\n",
        "    row_value = []\n",
        "    for j in value_column_data[i]:\n",
        "      row_value.append(j)\n",
        "    y.add_row(row_value)\n",
        "\n",
        "  y.align = 'l'\n",
        "  print(y)"
      ],
      "metadata": {
        "id": "YWaR7b52dP9Y"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.exists(drive_path+'/Auc_hyperpara_df.pkl'):\n",
        "\n",
        "  max_tree_depth = [x for x in range(1,6)]\n",
        "  number_of_estimators =[100*x for x in range(1,11)]\n",
        "  AUC_SCORE,auc_pretty_table = Auc_score(X_train, Y_train, max_tree_depth,number_of_estimators)\n",
        "\n",
        "  auc_pretty_table = [(x[0],x[1],x[2],x[3],1-x[3],x[3]-x[2]) for x in auc_pretty_table]\n",
        "  df_auc = pd.DataFrame(auc_pretty_table,columns=['No of estimators','Max leaf node in tree','CV AUC','Train AUC','Bias','variance'])\n",
        "  pickle.dump(df_auc,open(drive_path+'/Auc_hyperpara_df.pkl','wb')) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uuqL0dj3dQAG",
        "outputId": "1d587293-6d92-4ab6-ccb8-fc382d7d3846"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/10 [00:00<?, ?it/s]\n",
            "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
            " 20%|██        | 1/5 [01:19<05:19, 79.95s/it]\u001b[A\n",
            " 40%|████      | 2/5 [02:41<04:02, 80.73s/it]\u001b[A\n",
            " 60%|██████    | 3/5 [04:06<02:45, 82.97s/it]\u001b[A\n",
            " 80%|████████  | 4/5 [05:36<01:25, 85.66s/it]\u001b[A\n",
            "100%|██████████| 5/5 [07:11<00:00, 86.35s/it]\n",
            " 10%|█         | 1/10 [07:11<1:04:45, 431.77s/it]\n",
            "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
            " 20%|██        | 1/5 [01:35<06:20, 95.20s/it]\u001b[A\n",
            " 40%|████      | 2/5 [03:16<04:56, 98.74s/it]\u001b[A\n",
            " 60%|██████    | 3/5 [05:08<03:29, 104.78s/it]\u001b[A\n",
            " 80%|████████  | 4/5 [07:10<01:51, 111.45s/it]\u001b[A\n",
            "100%|██████████| 5/5 [09:21<00:00, 112.28s/it]\n",
            " 20%|██        | 2/10 [16:33<1:07:44, 508.03s/it]\n",
            "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
            " 20%|██        | 1/5 [01:56<07:45, 116.41s/it]\u001b[A\n",
            " 40%|████      | 2/5 [03:59<06:00, 120.10s/it]\u001b[A\n",
            " 60%|██████    | 3/5 [06:10<04:10, 125.26s/it]\u001b[A\n",
            " 80%|████████  | 4/5 [08:36<02:13, 133.64s/it]\u001b[A\n",
            "100%|██████████| 5/5 [11:19<00:00, 135.86s/it]\n",
            " 30%|███       | 3/10 [27:52<1:08:23, 586.25s/it]\n",
            "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
            " 20%|██        | 1/5 [02:10<08:42, 130.75s/it]\u001b[A\n",
            " 40%|████      | 2/5 [04:35<06:56, 138.85s/it]\u001b[A\n",
            " 60%|██████    | 3/5 [07:09<04:51, 145.98s/it]\u001b[A\n",
            " 80%|████████  | 4/5 [10:01<02:35, 155.98s/it]\u001b[A\n",
            "100%|██████████| 5/5 [13:16<00:00, 159.30s/it]\n",
            " 40%|████      | 4/10 [41:09<1:06:55, 669.25s/it]\n",
            "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
            " 20%|██        | 1/5 [02:30<10:01, 150.35s/it]\u001b[A\n",
            " 40%|████      | 2/5 [05:20<08:06, 162.29s/it]\u001b[A\n",
            " 60%|██████    | 3/5 [08:29<05:48, 174.05s/it]\u001b[A\n",
            " 80%|████████  | 4/5 [11:56<03:07, 187.29s/it]\u001b[A\n",
            "100%|██████████| 5/5 [15:51<00:00, 190.37s/it]\n",
            " 50%|█████     | 5/10 [57:00<1:04:15, 771.16s/it]\n",
            "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
            " 20%|██        | 1/5 [02:51<11:26, 171.65s/it]\u001b[A\n",
            " 40%|████      | 2/5 [05:58<09:02, 180.86s/it]\u001b[A\n",
            " 60%|██████    | 3/5 [09:21<06:21, 190.65s/it]\u001b[A\n",
            " 80%|████████  | 4/5 [13:08<03:25, 205.18s/it]\u001b[A\n",
            "100%|██████████| 5/5 [17:26<00:00, 209.29s/it]\n",
            " 60%|██████    | 6/10 [1:14:27<57:39, 864.76s/it]\n",
            "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
            " 20%|██        | 1/5 [03:00<12:03, 180.84s/it]\u001b[A\n",
            " 40%|████      | 2/5 [06:20<09:35, 191.71s/it]\u001b[A\n",
            " 60%|██████    | 3/5 [10:07<06:55, 207.96s/it]\u001b[A\n",
            " 80%|████████  | 4/5 [14:21<03:46, 226.03s/it]\u001b[A\n",
            "100%|██████████| 5/5 [19:14<00:00, 230.92s/it]\n",
            " 70%|███████   | 7/10 [1:33:41<47:58, 959.52s/it]\n",
            "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
            " 20%|██        | 1/5 [03:16<13:04, 196.22s/it]\u001b[A\n",
            " 40%|████      | 2/5 [06:59<10:35, 211.88s/it]\u001b[A\n",
            " 60%|██████    | 3/5 [11:19<07:48, 234.03s/it]\u001b[A\n",
            " 80%|████████  | 4/5 [16:16<04:19, 259.09s/it]\u001b[A\n",
            "100%|██████████| 5/5 [22:00<00:00, 264.15s/it]\n",
            " 80%|████████  | 8/10 [1:55:42<35:49, 1074.53s/it]\n",
            "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
            " 20%|██        | 1/5 [03:42<14:51, 222.80s/it]\u001b[A\n",
            " 40%|████      | 2/5 [07:54<12:00, 240.06s/it]\u001b[A\n",
            " 60%|██████    | 3/5 [12:26<08:28, 254.47s/it]\u001b[A\n",
            " 80%|████████  | 4/5 [17:37<04:36, 276.65s/it]\u001b[A\n",
            "100%|██████████| 5/5 [23:37<00:00, 283.43s/it]\n",
            " 90%|█████████ | 9/10 [2:19:19<19:41, 1181.64s/it]\n",
            "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
            " 20%|██        | 1/5 [03:48<15:14, 228.64s/it]\u001b[A\n",
            " 40%|████      | 2/5 [08:06<12:18, 246.09s/it]\u001b[A\n",
            " 60%|██████    | 3/5 [13:02<08:57, 268.63s/it]\u001b[A\n",
            " 80%|████████  | 4/5 [18:40<04:56, 296.18s/it]\u001b[A\n",
            "100%|██████████| 5/5 [25:28<00:00, 305.74s/it]\n",
            "100%|██████████| 10/10 [2:44:48<00:00, 988.86s/it] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# if not len(os.listdir(drive_path+'/model/xgb')) == 5:\n",
        "\n",
        "#   if not os.path.exists(drive_path+'/model'):\n",
        "#       os.makedirs(drive_path+'/model/txt')\n",
        "#       os.makedirs(drive_path+'/model/json')\n",
        "#       os.makedirs(drive_path+'/model/xgb')\n",
        "\n",
        "#   auc_df = pd.read_csv(drive_path+'/Auc_hyperpara_df.csv')\n",
        "#   auc_df = auc_df.sort_values(by=['AMX_train_score'],ascending=False)\n",
        "\n",
        "#   train_index ,cv_index, k_val = k_fold_index(X_train,Y_train)\n",
        "#   importances, oof , acc_main= [], [], []\n",
        "#   feature_name = pickle.load(open('/content/processors/feature_name.pkl','rb'))\n",
        "\n",
        "#   for i in range(k_val):\n",
        "#     clf = XGBClassifier(tree_method='gpu_hist',\n",
        "#                           max_depth=int(auc_df.iloc[0]['max_depth']),\n",
        "#                           n_estimators=int(auc_df.iloc[0]['n_estimetors']),\n",
        "#                           n_jobs=-1,\n",
        "#                           single_precision_histogram=True,\n",
        "#                           random_state=33\n",
        "#                         )\n",
        "#     clf.fit(X_train[train_index[i]],\n",
        "#             Y_train['target'].iloc[train_index[i]].values.reshape(-1,1))\n",
        "\n",
        "#     # saving Model\n",
        "\n",
        "#     clf.save_model(drive_path+'model/txt'+f'/model_{i}.txt')\n",
        "#     clf.save_model(drive_path+'model/json'+f'/model_{i}.json')\n",
        "#     clf.save_model(drive_path+'model/xgb'+f'/model_{i}.xgb')\n",
        "\n",
        "#     # getting the oof (out of fold prediction)\n",
        "#     # calculating feature importance for fold k\n",
        "\n",
        "\n",
        "#     dd_df = pd.DataFrame({'feature':feature_name, f'importance_{i}':list(clf.feature_importances_)})\n",
        "#     importances.append(dd_df)\n",
        "\n",
        "\n",
        "#     # infer the OOF (out of fold) of k fold\n",
        "#     oof_preds = clf.predict_proba(X_train[cv_index[i]])\n",
        "#     oof_df = Y_train.iloc[cv_index[i]]\n",
        "#     oof_df['prediction'] = oof_preds[:,1]\n",
        "\n",
        "#     oof.append(oof_df)\n",
        "\n",
        "#     # getting the AMEX score\n",
        "#     acc = score(Y_train['target'].iloc[cv_index[i]].values.reshape(-1,1),\n",
        "#                 oof_preds[:,1])\n",
        "#     acc_main.append(acc)\n",
        "#     print('AMEX Kaggle Metric =', acc, \"\\n\")\n",
        "\n",
        "#     _ = gc.collect()\n",
        "#     del dd_df, oof_preds, acc, oof_df\n",
        "\n",
        "#   oof_final = pd.concat(oof,axis=0,ignore_index=True).set_index('customer_ID')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rArjkZuC3Pvc",
        "outputId": "d8d034af-e5b5-43ba-d64d-dd6b1e1ebe1e"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AMEX Kaggle Metric = 0.7642671576369617 \n",
            "\n",
            "AMEX Kaggle Metric = 0.7694896595962263 \n",
            "\n",
            "AMEX Kaggle Metric = 0.7603632477501608 \n",
            "\n",
            "AMEX Kaggle Metric = 0.7659435616844168 \n",
            "\n",
            "AMEX Kaggle Metric = 0.7594366234430266 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "auc_df = pd.read_csv(drive_path+'/Auc_hyperpara_df.csv')\n",
        "auc_df = auc_df.sort_values(by=['AMX_val_score'],ascending=False)\n",
        "auc_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "RRpLSWBD_fAV",
        "outputId": "5109559a-9d30-4a23-f661-76e4cc0e5d34"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    n_estimetors  max_depth  train_AUC   val_AUC  AMX_train_score  \\\n",
              "22           500          3   0.953999  0.960977         0.802643   \n",
              "27           600          3   0.954107  0.961978         0.806734   \n",
              "17           400          3   0.953740  0.959730         0.798901   \n",
              "37           800          3   0.954137  0.963696         0.812203   \n",
              "32           700          3   0.954124  0.962871         0.809630   \n",
              "12           300          3   0.953433  0.958414         0.793320   \n",
              "13           300          4   0.953550  0.962827         0.811906   \n",
              "23           500          4   0.953602  0.967976         0.835488   \n",
              "18           400          4   0.953567  0.965551         0.824290   \n",
              "9            200          5   0.955735  0.968442         0.827788   \n",
              "47          1000          3   0.954088  0.965328         0.819800   \n",
              "33           700          4   0.953438  0.972199         0.854420   \n",
              "42           900          3   0.954137  0.964548         0.816110   \n",
              "7            200          3   0.952727  0.956538         0.786122   \n",
              "28           600          4   0.953498  0.970177         0.845703   \n",
              "8            200          4   0.952883  0.959423         0.798146   \n",
              "43           900          4   0.953138  0.975804         0.872965   \n",
              "4            100          5   0.955273  0.962586         0.800413   \n",
              "38           800          4   0.953229  0.974112         0.864090   \n",
              "14           300          5   0.955535  0.973373         0.852025   \n",
              "48          1000          4   0.952942  0.977429         0.881206   \n",
              "19           400          5   0.955162  0.977439         0.871357   \n",
              "24           500          5   0.954820  0.981010         0.889692   \n",
              "34           700          5   0.954163  0.987034         0.918956   \n",
              "29           600          5   0.954488  0.984094         0.906842   \n",
              "2            100          3   0.950013  0.952362         0.774116   \n",
              "39           800          5   0.953900  0.989196         0.924595   \n",
              "3            100          4   0.950401  0.954131         0.773399   \n",
              "44           900          5   0.953715  0.991062         0.935348   \n",
              "49          1000          5   0.953498  0.992627         0.946467   \n",
              "45          1000          1   0.879044  0.879766         0.701668   \n",
              "40           900          1   0.874614  0.875147         0.701764   \n",
              "5            200          1   0.889665  0.889798         0.694442   \n",
              "35           800          1   0.880812  0.881585         0.700501   \n",
              "30           700          1   0.881702  0.882471         0.698277   \n",
              "46          1000          2   0.935615  0.942644         0.719901   \n",
              "41           900          2   0.935264  0.941883         0.716856   \n",
              "20           500          1   0.881055  0.881654         0.691988   \n",
              "15           400          1   0.881864  0.882275         0.691512   \n",
              "0            100          1   0.905252  0.905285         0.689122   \n",
              "36           800          2   0.935027  0.941141         0.713425   \n",
              "31           700          2   0.934743  0.940437         0.709604   \n",
              "26           600          2   0.934160  0.939535         0.704553   \n",
              "10           300          1   0.880370  0.881456         0.683733   \n",
              "25           600          1   0.879486  0.880117         0.686450   \n",
              "21           500          2   0.933353  0.938226         0.695511   \n",
              "16           400          2   0.931207  0.935430         0.676533   \n",
              "11           300          2   0.929007  0.932264         0.659790   \n",
              "6            200          2   0.926273  0.929005         0.651500   \n",
              "1            100          2   0.921594  0.922055         0.618658   \n",
              "\n",
              "    AMX_val_score  \n",
              "22       0.772837  \n",
              "27       0.772337  \n",
              "17       0.772053  \n",
              "37       0.771834  \n",
              "32       0.771763  \n",
              "12       0.771350  \n",
              "13       0.771204  \n",
              "23       0.770809  \n",
              "18       0.770737  \n",
              "9        0.770356  \n",
              "47       0.770246  \n",
              "33       0.770007  \n",
              "42       0.769960  \n",
              "7        0.769938  \n",
              "28       0.769337  \n",
              "8        0.769185  \n",
              "43       0.768696  \n",
              "4        0.768325  \n",
              "38       0.767909  \n",
              "14       0.767818  \n",
              "48       0.767703  \n",
              "19       0.767162  \n",
              "24       0.765301  \n",
              "34       0.764007  \n",
              "29       0.763304  \n",
              "2        0.761877  \n",
              "39       0.761834  \n",
              "3        0.760029  \n",
              "44       0.759921  \n",
              "49       0.759437  \n",
              "45       0.697153  \n",
              "40       0.696582  \n",
              "5        0.694956  \n",
              "35       0.694385  \n",
              "30       0.692377  \n",
              "46       0.692295  \n",
              "41       0.691516  \n",
              "20       0.690346  \n",
              "15       0.690056  \n",
              "0        0.689169  \n",
              "36       0.688720  \n",
              "31       0.688097  \n",
              "26       0.685560  \n",
              "10       0.683460  \n",
              "25       0.682581  \n",
              "21       0.678782  \n",
              "16       0.663862  \n",
              "11       0.646608  \n",
              "6        0.641452  \n",
              "1        0.616876  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6d03340c-3f89-4992-a586-558a89bd711e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>n_estimetors</th>\n",
              "      <th>max_depth</th>\n",
              "      <th>train_AUC</th>\n",
              "      <th>val_AUC</th>\n",
              "      <th>AMX_train_score</th>\n",
              "      <th>AMX_val_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>500</td>\n",
              "      <td>3</td>\n",
              "      <td>0.953999</td>\n",
              "      <td>0.960977</td>\n",
              "      <td>0.802643</td>\n",
              "      <td>0.772837</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>600</td>\n",
              "      <td>3</td>\n",
              "      <td>0.954107</td>\n",
              "      <td>0.961978</td>\n",
              "      <td>0.806734</td>\n",
              "      <td>0.772337</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>400</td>\n",
              "      <td>3</td>\n",
              "      <td>0.953740</td>\n",
              "      <td>0.959730</td>\n",
              "      <td>0.798901</td>\n",
              "      <td>0.772053</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>800</td>\n",
              "      <td>3</td>\n",
              "      <td>0.954137</td>\n",
              "      <td>0.963696</td>\n",
              "      <td>0.812203</td>\n",
              "      <td>0.771834</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>700</td>\n",
              "      <td>3</td>\n",
              "      <td>0.954124</td>\n",
              "      <td>0.962871</td>\n",
              "      <td>0.809630</td>\n",
              "      <td>0.771763</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>300</td>\n",
              "      <td>3</td>\n",
              "      <td>0.953433</td>\n",
              "      <td>0.958414</td>\n",
              "      <td>0.793320</td>\n",
              "      <td>0.771350</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>300</td>\n",
              "      <td>4</td>\n",
              "      <td>0.953550</td>\n",
              "      <td>0.962827</td>\n",
              "      <td>0.811906</td>\n",
              "      <td>0.771204</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>500</td>\n",
              "      <td>4</td>\n",
              "      <td>0.953602</td>\n",
              "      <td>0.967976</td>\n",
              "      <td>0.835488</td>\n",
              "      <td>0.770809</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>400</td>\n",
              "      <td>4</td>\n",
              "      <td>0.953567</td>\n",
              "      <td>0.965551</td>\n",
              "      <td>0.824290</td>\n",
              "      <td>0.770737</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>200</td>\n",
              "      <td>5</td>\n",
              "      <td>0.955735</td>\n",
              "      <td>0.968442</td>\n",
              "      <td>0.827788</td>\n",
              "      <td>0.770356</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>1000</td>\n",
              "      <td>3</td>\n",
              "      <td>0.954088</td>\n",
              "      <td>0.965328</td>\n",
              "      <td>0.819800</td>\n",
              "      <td>0.770246</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>700</td>\n",
              "      <td>4</td>\n",
              "      <td>0.953438</td>\n",
              "      <td>0.972199</td>\n",
              "      <td>0.854420</td>\n",
              "      <td>0.770007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>900</td>\n",
              "      <td>3</td>\n",
              "      <td>0.954137</td>\n",
              "      <td>0.964548</td>\n",
              "      <td>0.816110</td>\n",
              "      <td>0.769960</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>200</td>\n",
              "      <td>3</td>\n",
              "      <td>0.952727</td>\n",
              "      <td>0.956538</td>\n",
              "      <td>0.786122</td>\n",
              "      <td>0.769938</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>600</td>\n",
              "      <td>4</td>\n",
              "      <td>0.953498</td>\n",
              "      <td>0.970177</td>\n",
              "      <td>0.845703</td>\n",
              "      <td>0.769337</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>200</td>\n",
              "      <td>4</td>\n",
              "      <td>0.952883</td>\n",
              "      <td>0.959423</td>\n",
              "      <td>0.798146</td>\n",
              "      <td>0.769185</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>900</td>\n",
              "      <td>4</td>\n",
              "      <td>0.953138</td>\n",
              "      <td>0.975804</td>\n",
              "      <td>0.872965</td>\n",
              "      <td>0.768696</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>100</td>\n",
              "      <td>5</td>\n",
              "      <td>0.955273</td>\n",
              "      <td>0.962586</td>\n",
              "      <td>0.800413</td>\n",
              "      <td>0.768325</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>800</td>\n",
              "      <td>4</td>\n",
              "      <td>0.953229</td>\n",
              "      <td>0.974112</td>\n",
              "      <td>0.864090</td>\n",
              "      <td>0.767909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>300</td>\n",
              "      <td>5</td>\n",
              "      <td>0.955535</td>\n",
              "      <td>0.973373</td>\n",
              "      <td>0.852025</td>\n",
              "      <td>0.767818</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>1000</td>\n",
              "      <td>4</td>\n",
              "      <td>0.952942</td>\n",
              "      <td>0.977429</td>\n",
              "      <td>0.881206</td>\n",
              "      <td>0.767703</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>400</td>\n",
              "      <td>5</td>\n",
              "      <td>0.955162</td>\n",
              "      <td>0.977439</td>\n",
              "      <td>0.871357</td>\n",
              "      <td>0.767162</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>500</td>\n",
              "      <td>5</td>\n",
              "      <td>0.954820</td>\n",
              "      <td>0.981010</td>\n",
              "      <td>0.889692</td>\n",
              "      <td>0.765301</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>700</td>\n",
              "      <td>5</td>\n",
              "      <td>0.954163</td>\n",
              "      <td>0.987034</td>\n",
              "      <td>0.918956</td>\n",
              "      <td>0.764007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>600</td>\n",
              "      <td>5</td>\n",
              "      <td>0.954488</td>\n",
              "      <td>0.984094</td>\n",
              "      <td>0.906842</td>\n",
              "      <td>0.763304</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>100</td>\n",
              "      <td>3</td>\n",
              "      <td>0.950013</td>\n",
              "      <td>0.952362</td>\n",
              "      <td>0.774116</td>\n",
              "      <td>0.761877</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>800</td>\n",
              "      <td>5</td>\n",
              "      <td>0.953900</td>\n",
              "      <td>0.989196</td>\n",
              "      <td>0.924595</td>\n",
              "      <td>0.761834</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>100</td>\n",
              "      <td>4</td>\n",
              "      <td>0.950401</td>\n",
              "      <td>0.954131</td>\n",
              "      <td>0.773399</td>\n",
              "      <td>0.760029</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>900</td>\n",
              "      <td>5</td>\n",
              "      <td>0.953715</td>\n",
              "      <td>0.991062</td>\n",
              "      <td>0.935348</td>\n",
              "      <td>0.759921</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>1000</td>\n",
              "      <td>5</td>\n",
              "      <td>0.953498</td>\n",
              "      <td>0.992627</td>\n",
              "      <td>0.946467</td>\n",
              "      <td>0.759437</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>1000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.879044</td>\n",
              "      <td>0.879766</td>\n",
              "      <td>0.701668</td>\n",
              "      <td>0.697153</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>900</td>\n",
              "      <td>1</td>\n",
              "      <td>0.874614</td>\n",
              "      <td>0.875147</td>\n",
              "      <td>0.701764</td>\n",
              "      <td>0.696582</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>200</td>\n",
              "      <td>1</td>\n",
              "      <td>0.889665</td>\n",
              "      <td>0.889798</td>\n",
              "      <td>0.694442</td>\n",
              "      <td>0.694956</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>800</td>\n",
              "      <td>1</td>\n",
              "      <td>0.880812</td>\n",
              "      <td>0.881585</td>\n",
              "      <td>0.700501</td>\n",
              "      <td>0.694385</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>700</td>\n",
              "      <td>1</td>\n",
              "      <td>0.881702</td>\n",
              "      <td>0.882471</td>\n",
              "      <td>0.698277</td>\n",
              "      <td>0.692377</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>1000</td>\n",
              "      <td>2</td>\n",
              "      <td>0.935615</td>\n",
              "      <td>0.942644</td>\n",
              "      <td>0.719901</td>\n",
              "      <td>0.692295</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>900</td>\n",
              "      <td>2</td>\n",
              "      <td>0.935264</td>\n",
              "      <td>0.941883</td>\n",
              "      <td>0.716856</td>\n",
              "      <td>0.691516</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>500</td>\n",
              "      <td>1</td>\n",
              "      <td>0.881055</td>\n",
              "      <td>0.881654</td>\n",
              "      <td>0.691988</td>\n",
              "      <td>0.690346</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>400</td>\n",
              "      <td>1</td>\n",
              "      <td>0.881864</td>\n",
              "      <td>0.882275</td>\n",
              "      <td>0.691512</td>\n",
              "      <td>0.690056</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>100</td>\n",
              "      <td>1</td>\n",
              "      <td>0.905252</td>\n",
              "      <td>0.905285</td>\n",
              "      <td>0.689122</td>\n",
              "      <td>0.689169</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>800</td>\n",
              "      <td>2</td>\n",
              "      <td>0.935027</td>\n",
              "      <td>0.941141</td>\n",
              "      <td>0.713425</td>\n",
              "      <td>0.688720</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>700</td>\n",
              "      <td>2</td>\n",
              "      <td>0.934743</td>\n",
              "      <td>0.940437</td>\n",
              "      <td>0.709604</td>\n",
              "      <td>0.688097</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>600</td>\n",
              "      <td>2</td>\n",
              "      <td>0.934160</td>\n",
              "      <td>0.939535</td>\n",
              "      <td>0.704553</td>\n",
              "      <td>0.685560</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>300</td>\n",
              "      <td>1</td>\n",
              "      <td>0.880370</td>\n",
              "      <td>0.881456</td>\n",
              "      <td>0.683733</td>\n",
              "      <td>0.683460</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>600</td>\n",
              "      <td>1</td>\n",
              "      <td>0.879486</td>\n",
              "      <td>0.880117</td>\n",
              "      <td>0.686450</td>\n",
              "      <td>0.682581</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>500</td>\n",
              "      <td>2</td>\n",
              "      <td>0.933353</td>\n",
              "      <td>0.938226</td>\n",
              "      <td>0.695511</td>\n",
              "      <td>0.678782</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>400</td>\n",
              "      <td>2</td>\n",
              "      <td>0.931207</td>\n",
              "      <td>0.935430</td>\n",
              "      <td>0.676533</td>\n",
              "      <td>0.663862</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>300</td>\n",
              "      <td>2</td>\n",
              "      <td>0.929007</td>\n",
              "      <td>0.932264</td>\n",
              "      <td>0.659790</td>\n",
              "      <td>0.646608</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>200</td>\n",
              "      <td>2</td>\n",
              "      <td>0.926273</td>\n",
              "      <td>0.929005</td>\n",
              "      <td>0.651500</td>\n",
              "      <td>0.641452</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>100</td>\n",
              "      <td>2</td>\n",
              "      <td>0.921594</td>\n",
              "      <td>0.922055</td>\n",
              "      <td>0.618658</td>\n",
              "      <td>0.616876</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6d03340c-3f89-4992-a586-558a89bd711e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6d03340c-3f89-4992-a586-558a89bd711e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6d03340c-3f89-4992-a586-558a89bd711e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if not len(os.listdir(drive_path+'/model/xgb')) == 5:\n",
        "\n",
        "  if not os.path.exists(drive_path+'/model'):\n",
        "      os.makedirs(drive_path+'/model/txt')\n",
        "      os.makedirs(drive_path+'/model/json')\n",
        "      os.makedirs(drive_path+'/model/xgb')\n",
        "\n",
        "  auc_df = pd.read_csv(drive_path+'/Auc_hyperpara_df.csv')\n",
        "  auc_df = auc_df.sort_values(by=['AMX_val_score'],ascending=False)\n",
        "\n",
        "  train_index ,cv_index, k_val = k_fold_index(X_train,Y_train)\n",
        "  importances, oof , acc_main= [], [], []\n",
        "  feature_name = pickle.load(open('/content/processors/feature_name.pkl','rb'))\n",
        "\n",
        "  for i in range(k_val):\n",
        "    clf = XGBClassifier(tree_method='gpu_hist',\n",
        "                          max_depth=int(auc_df.iloc[0]['max_depth']),\n",
        "                          n_estimators=int(auc_df.iloc[0]['n_estimetors']),\n",
        "                          n_jobs=-1,\n",
        "                          single_precision_histogram=True,\n",
        "                          random_state=33\n",
        "                        )\n",
        "    clf.fit(X_train[train_index[i]],\n",
        "            Y_train['target'].iloc[train_index[i]].values.reshape(-1,1))\n",
        "\n",
        "    # saving Model\n",
        "\n",
        "    clf.save_model(drive_path+'/model/txt'+f'/model_{i}.txt')\n",
        "    clf.save_model(drive_path+'/model/json'+f'/model_{i}.json')\n",
        "    clf.save_model(drive_path+'/model/xgb'+f'/model_{i}.xgb')\n",
        "\n",
        "    # getting the oof (out of fold prediction)\n",
        "    # calculating feature importance for fold k\n",
        "\n",
        "\n",
        "    dd_df = pd.DataFrame({'feature':feature_name, f'importance_{i}':list(clf.feature_importances_)})\n",
        "    importances.append(dd_df)\n",
        "\n",
        "\n",
        "    # infer the OOF (out of fold) of k fold\n",
        "    oof_preds = clf.predict_proba(X_train[cv_index[i]])\n",
        "    oof_df = Y_train.iloc[cv_index[i]]\n",
        "    oof_df['prediction'] = oof_preds[:,1]\n",
        "\n",
        "    oof.append(oof_df)\n",
        "\n",
        "    # getting the AMEX score\n",
        "    acc = score(Y_train['target'].iloc[cv_index[i]].values.reshape(-1,1),\n",
        "                oof_preds[:,1])\n",
        "    acc_main.append(acc)\n",
        "    print('AMEX Kaggle Metric =', acc, \"\\n\")\n",
        "\n",
        "    _ = gc.collect()\n",
        "    del dd_df, oof_preds, acc, oof_df\n",
        "\n",
        "  oof_final = pd.concat(oof,axis=0,ignore_index=True).set_index('customer_ID')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uA6SPGqx_KBw",
        "outputId": "010010b9-da33-4072-da96-6d00328b22ac"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AMEX Kaggle Metric = 0.7740122201239236 \n",
            "\n",
            "AMEX Kaggle Metric = 0.7690306640141068 \n",
            "\n",
            "AMEX Kaggle Metric = 0.7724703375508509 \n",
            "\n",
            "AMEX Kaggle Metric = 0.7725204050324884 \n",
            "\n",
            "AMEX Kaggle Metric = 0.772837330456773 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_val,Y_val = load_data('val')"
      ],
      "metadata": {
        "id": "n0T2u7oHBmhM"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(5):\n",
        "  if i == 0:\n",
        "    model = xgb.XGBClassifier()\n",
        "    model.load_model(drive_path+'/model/xgb'+f'/model_{i}.xgb')\n",
        "\n",
        "    preds = model.predict_proba(X_val)\n",
        "  else:\n",
        "    model.load_model(drive_path+'/model/xgb'+f'/model_{i}.xgb')\n",
        "    preds += model.predict_proba(X_val)"
      ],
      "metadata": {
        "id": "DfjO3dtJBmeP"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# score with highest val AMEX score\n",
        "\n",
        "print(f\"AMEX score for the Out Of Bag set is : {score(oof_final['target'],oof_final['prediction'])}\")\n",
        "print(f'AMEX score for the validation set is : {score(Y_val,(preds/5)[:,1])}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KIZFmlrxEHVU",
        "outputId": "f20b8087-1cfc-4a70-dd66-be0f8750791e"
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AMEX score for the Out Of Bag set is : 0.7721844842278176\n",
            "AMEX score for the validation set is : 0.785203200313423\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Saving Model:"
      ],
      "metadata": {
        "id": "Q2ePk29YPd2w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score,roc_curve, f1_score\n",
        "fpr,tpr,ther = roc_curve(oof_final['target'],oof_final['prediction'])\n",
        "best_ther = [(x[0],x[2]*(1-x[1])) for x in zip(ther,fpr,tpr)]\n",
        "\n",
        "thersold = max(best_ther,key=lambda x:x[1])\n",
        "pickle.dump(thersold[0],open(drive_path+'/default_thersold.pkl','wb'))"
      ],
      "metadata": {
        "id": "qjZwXHuRWudV"
      },
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def confusion_matrix_plotter(y_test,y_test_pred,model,para,best_para):\n",
        "\n",
        "\n",
        "  print(f'For {model} Classifier:')\n",
        "  n = len(y_test)\n",
        "  y_test_pred = [(1 if x >best_para else 0 ) for x in y_test_pred]\n",
        "  C = confusion_matrix(y_test,y_test_pred)\n",
        "  labels = [0,1]\n",
        "\n",
        "  precision = (((C.T)/(C.sum(axis=1))).T)\n",
        "  recall = (C/C.sum(axis=0))\n",
        "\n",
        "\n",
        "  missclassified_point = ((n-np.trace(C))/n)*100\n",
        "  print(f\"\\t\\tTotal % Of Missclassified Points : {missclassified_point}%\\n\")\n",
        "  print(f\"\\t\\tF1 Score : {f1_score(y_test,y_test_pred)}%\\n\")\n",
        "\n",
        "  print('\\n',\"-\"*50, \"Confusion matrix\", \"-\"*50,'\\n')\n",
        "\n",
        "  plt.figure(figsize=[15,5])\n",
        "  labels = [0,1]\n",
        "  c_map = sns.light_palette(\"green\")\n",
        "  sns.heatmap(C,annot=True,cmap=c_map,fmt=\".3f\", xticklabels=labels, yticklabels=labels)\n",
        "  plt.xlabel('Predicted Class')\n",
        "  plt.ylabel('True Class')\n",
        "  plt.title('\\n\"ConFusion Matrix\"\\n')\n",
        "  plt.show()\n",
        "\n",
        "  print('\\n',\"-\"*50, \"Precision matrix\", \"-\"*50,'\\n')\n",
        "\n",
        "  plt.figure(figsize=[15,5])\n",
        "  labels = [0,1]\n",
        "  c_map = sns.light_palette(\"green\")\n",
        "  sns.heatmap(precision,annot=True,cmap=c_map,fmt=\".3f\", xticklabels=labels, yticklabels=labels)\n",
        "  plt.xlabel('Predicted Class')\n",
        "  plt.ylabel('True Class')\n",
        "  plt.title(\"\\nPrecision Matrix\\n\")\n",
        "  plt.show()\n",
        "\n",
        "  print('\\n',\"-\"*50, \"Recall matrix\"    , \"-\"*50,'\\n')\n",
        "\n",
        "  plt.figure(figsize=[15,5])\n",
        "  labels = [0,1]\n",
        "  c_map = sns.light_palette(\"green\")\n",
        "  sns.heatmap(recall,annot=True,cmap=c_map,fmt=\".3f\", xticklabels=labels, yticklabels=labels)\n",
        "  plt.xlabel('Predicted Class')\n",
        "  plt.ylabel('True Class')\n",
        "  plt.title('\\nRecall Matrix\\n')"
      ],
      "metadata": {
        "id": "37geBTV8bX3U"
      },
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "confusion_matrix_plotter(Y_val['target'],(preds/5)[:,1],model='xgb',para='thersol',best_para=thersold[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "byk1nSIOGlLw",
        "outputId": "23c7017e-1dfb-4607-db12-9e6454ca2736"
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For xgb Classifier:\n",
            "\t\tTotal % Of Missclassified Points : 11.728751511717856%\n",
            "\n",
            "\t\tF1 Score : 0.8018407731247124%\n",
            "\n",
            "\n",
            " -------------------------------------------------- Confusion matrix -------------------------------------------------- \n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1080x360 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " -------------------------------------------------- Precision matrix -------------------------------------------------- \n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1080x360 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " -------------------------------------------------- Recall matrix -------------------------------------------------- \n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1080x360 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxkAAAFrCAYAAAC9lkQcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3debiWVb3/8fcXNooxqgypjCoOaGLOmQqKhlpJNph2yAaN8mRWph09dTQ1U082/rLB+WiD2dEUlcQDOZWZgIIKiCJIDCqQkIoTsL+/P/YDbhA2G1zP3m72+3Vd++JZ6173ur/3/mNfz4d1r+eJzESSJEmSSmnT3AVIkiRJ2rQYMiRJkiQVZciQJEmSVJQhQ5IkSVJRhgxJkiRJRRkyJEmSJBVlyJAkSZJUlCFDkiRJUlGGDEmSJElFGTIkSZIkFWXIkCRJklSUIUOSJElSUYYMSZIkSUUZMiRJkiQVZciQJEmSVJQhQ5IkSVJRhgxJkiRJRRkyJEmSJBVlyJAkSZJUlCFDkiRJUlGGDEmSJElFGTIkqYWIiHsi4uTK689GxF+auyaAiPhlRPxXc9chSXrnMGRI0kaIiGci4tWIeDkinouIayOiY3PXBRAR/SIiI+KRNfq7RcQbEfFMI+dpVJDJzC9l5gUbWa4kaRNkyJCkjffhzOwI7Am8Fzi7metZ07siYvd67U8Bs0peICLalpxPkrRpMGRI0tuUmc8BY6gLGwBExAER8UBELImIyRExpN6xrSLimoiYHxGLI+KWSv+WEXF7RCys9N8eEb3eRmnXA5+p1z4RuK7+gIg4KyKejoiXImJqRBxb6d8V+CXwvspqzZJK/7UR8YuIGB0RS4FDK33frRz/j4j4e0TUVNqnRMSUiGj/Nu5DktTCGDIk6W2qBIGjgBmV9nbAHcB3ga2AM4CbIqJ75ZTrgXcBuwE9gB9V+tsA1wB9gT7Aq8DP3kZpvwaOj4i2ETEQ6Aj8fY0xTwMHA12A84BfR8Q2mTkN+BLwt8zsmJld653zKeBCoBOw5uNU3wdeB74dEQOA7wEjMvO1t3EfkqQWpqa5C5CkFuyWiEjq3rz/GTi30j8CGJ2Zoyvt/4uICcDREXEXdYFk68xcXDl+L0Bm/hO4aeXkEXEhcPfbqG8uMB04HDiUunCzmsz8Q73m7yPibGA/4NYG5r01M/9aef1aRNSfrzYiTgQeBj4J/HdmPrKWOSRJmzBXMiRp430kMzsBQ4BdgG6V/r7AJyqPSi2pPGp0ELAN0Bt4oV7AWCUi3hURv4qI2RHxInAf0PVt7nu4DvgscAJrCRkRcWJETKpX5+717mNd5jR0MDOfoS4c9QMu2/CSJUktnSFDkt6mzLwXuBa4tNI1B7g+M7vW++mQmRdXjm0VEV3XMtU3gJ2B/TOzM3BIpT/WMraxbgI+CMzMzH/UPxARfYErgFOpW1npCjxe73q5jjnX1b9y3g8C7wPGUff4lCSplTFkSFIZPwaOiIhB1O2F+HBEDKvsh2gfEUMioldmPgv8Cfh5ZaN3u4hYGSY6UbcPY0lEbMWbj19ttMxcChwGnLyWwx2oCwwLASLic9StZKz0PNArIjZr7PUiohtwZeV6n6Hu93D0xlUvSWqpDBmSVEBmLqTu0aRzMnMOMBz4T+rewM8BzuTNv7mfBpYBTwALgK9V+n8MbAEsAh4E7ixU24TMfHot/VOBHwB/oy5QvAf4a70hfwamAM9FxKJGXu5y6vZsjK7sMTkJuDIitn479yBJalkis8FVb0mSJEnaIK5kSJIkSSrKkCFJkiSpKEOGJEmSpKIMGZIkSZKKMmRIkiRJKsqQIUmSJKkoQ4YkSZKkogwZkiRJkooyZEiSJEkqypAhSZIkqShDhiRJkqSiDBmSJEmSijJkSJIkSSrKkCFJkiSpKEOGJEmSpKIMGZIkSZKKMmRIkiRJKsqQIUmSJKkoQ4YkSZKkogwZkiRJkoqqae4C1iXOi2zuGiSppRk7YmxzlyBJLc7QHYZGc9fQGBvz/jjPzWa5N1cyJEmSJBVlyJAkSZJUlCFDkiRJUlGGDEmSJElFGTIkSZIkFWXIkCRJklSUIUOSJElSUYYMSZIkSUUZMiRJkiQVZciQJEmSVJQhQ5IkSVJRhgxJkiRJRRkyJEmSJBVlyJAkSZJUlCFDkiRJUlGGDEmSJElFGTIkSZIkFWXIkCRJklSUIUOSJElSUYYMSZIkSUUZMiRJkiQVZciQJEmSVJQhQ5IkSVJRhgxJkiRJRRkyJEmSJBVlyJAkSZJUlCFDkiRJUlGGDEmSJElFGTIkSZIkFWXIkCRJklSUIUOSJElSUYYMSZIkSUUZMiRJkiQVZciQJEmSVJQhQ5IkSVJRhgxJkiRJRRkyJEmSJBVlyJAkSZJUlCFDkiRJUlGGDEmSJElFGTIkSZIkFWXIkCRJklSUIUOSJElSUYYMSZIkSUUZMiRJkqRWLCKOjIjpETEjIs5ay/E+EXF3RDwSEY9GxNHrm7OmOqVKkiRJKmlQz0HF54yItsBlwBHAXGB8RIzKzKn1hn0buDEzfxERA4HRQL+G5nUlQ5IkSWq99gNmZObMzHwDuAEYvsaYBDpXXncB5q9vUlcyJEmSpNZrO2BOvfZcYP81xnwHuCsivgJ0AA5f36SuZEiSJEmbqIgYGRET6v2M3IhpTgCuzcxewNHA9RHRYI5wJUOSJEnaRGXm5cDlDQyZB/Su1+5V6avvJODIynx/i4j2QDdgwbomdSVDkiRJar3GAwMion9EbAYcD4xaY8w/gKEAEbEr0B5Y2NCkhgxJkiSplcrM5cCpwBhgGnWfIjUlIs6PiGMqw74BfCEiJgO/Az6bmdnQvD4uJUmSJLVimTmauo+lrd93Tr3XU4H3b8icrmRIkiRJKsqQIUmSJKkoQ4YkSZKkogwZkiRJkooyZEiSJEkqypAhSZIkqShDhiRJkqSiDBmSJEmSijJkSJIkSSrKb/xWqzdsh2H85Mif0LZNW658+Eou+eslqx3v06UPVx9zNd07dOeFV19gxM0jmPfSPAB6d+7NlcdcSe/OvUmSo39zNLP/NZvD+h/G94/4Pm2iDS+/8TKfveWzPL346ea4PUmqiikTpvCHX/2BrE0OHHYgw44bttrxcTeP469j/kqbtm3o1KUTI742gq17bg3AzVfdzJTxU6jNWnZ976584ouf4PVXX+eH3/zhqvMXL1rMfofuxye++IkmvS9JZRgy1Kq1iTZcdvRlHHH9Ecx9cS7jvzCeUdNHMW3RtFVjLj3iUq579Dqum3wdh/Y7lIuGXsSJt5wIwHXHXseF91/I2Jlj6dCuA7VZC8AvPvgLht8wnCcWPcEp+5zCtw/5Np+79XPNco+SVFrtilp+//Pfc9qFp9G1W1cu+dol7HHAHmzTZ5tVY3rt0IuzfnIWm7XfjPvuuI8/Xv1HTj77ZJ6e+jQzp87kW5d9C4AfnPkDnnrsKXbaYyf+82f/uer8i067iD0P3LPJ701SGT4upVZtv+32Y8YLM5i1ZBbLapdxw5QbGL7L8NXGDOw+kD/P+jMAdz9z96rju3bblZo2NYydORaApcuW8uryVwHITDpv3hmALu27MP+l+U11S5JUdc88+Qzdt+1Ot226UdOuhr0P2ZvJf5u82pidB+3MZu03A6D/Lv1ZsmgJABHBsmXLWL58OcuXLWfF8hV06tpptXOfn/s8Ly15iR1337FpbkhScVVbyYiIXYDhwHaVrnnAqMyctu6zpKa1XaftmPPinFXtuS/OZf/t9l9tzOTnJ/PRXT/KT//+U47d5Vg6b96ZrbbYip223oklry3hpuNuon/X/oydNZazxp5FbdZy8m0nM/pTo3l1+au8+PqLHHDlAU19a5JUNUv+uYQtu225qr1lty15Zvoz6xz/wJgH2G2f3QDYftft2WmPnTh7xNlkJoM/PHi1FRCAifdNZO9D9iYiqlK/pOqrykpGRPwHcAMQwEOVnwB+FxFnVeOaUrWccdcZDO47mIdHPszgfoOZ++JcVtSuoKZNDQf3OZgz7jqDfa/Yl+27bs9n9/wsAF8/4Osc/duj6f2j3lwz6Rp+OOyHDV9EkjZRf//z35n91GwO//jhACyYv4Dn5jzHhdddyPeu/x5PTn6SGY/PWO2cCfdOYN/B+zZHuZIKqdZKxknAbpm5rH5nRPwQmAJcvLaTImIkMBKADwH7VKk6qWLeS/Po3bn3qnavzr1Wbepe6dmXn+VjN34MgA7tOvCxXT/Gv17/F3NfnMuk5yYxa8ksAG6ZfgsH9DqAUdNHMajnIB6a9xAAv3/899w54s4muiNJqr6uW3dl8aLFq9qLFy2my9Zd3jLuiUee4M7f38npl5xOu3btAJj8wGT679yf9lu0B2C3fXZj5rSZqx6NmjtzLrUraukzoE8T3ImkaqnWnoxaYNu19G9TObZWmXl5Zu6TmfsYMNQUxs8bz4CtB9Cvaz/atWnH8bsdz6jpo1Ybs/UWWxPULdmfffDZXP3I1XXnzh9P1/Zd6faubgAc1u8wpi6cyuJXF9OlfRcGbDUAgCN2OIJpC31KUNKmo+9OfVkwfwGLnlvE8mXLmXjfRPY4YI/Vxsx5eg6//X+/5ZRzTlltz8WW3bfkqcefYsWKFaxYvoKnHnuKd/d596rjE+6dwD5DfBMgtXTVWsn4GjAuIp4CVj7w3gfYETi1SteUNtiKXMGpo09lzIgxtI22XD3paqYunMp5Q85jwvwJ3PbkbQzpN4SLhl5Ektw3+z6+PPrLANRmLWf83xmMO3EcQTDx2YlcMfEKVuQKvnDbF7jpuJuozVoWv7aYz9/6+Wa+U0kqp23btnzylE/ys2//jNraWt73gfexbd9tue362+g7oC97HLAHN191M6+/9jpXXnQlUBcuTjn3FPY6aC+efPRJvvvv3yUIBu49kD32fzOgTLx/Il8+78vNdWuSConMrM7EEW2A/Vh94/f4zFzRqPPPi+oUJkmbsLEjxjZ3CZLU4gzdYWiL+JSBPX+55wa/P570pUnNcm9V+3SpzKwFHqzW/JIkSZLemfyeDEmSJElFGTIkSZIkFWXIkCRJklSUIUOSJElSUYYMSZIkSUUZMiRJkiQVZciQJEmSVJQhQ5IkSVJRhgxJkiRJRRkyJEmSJBVlyJAkSZJUlCFDkiRJUlGGDEmSJElFGTIkSZIkFWXIkCRJklSUIUOSJElSUYYMSZIkSUUZMiRJkiQVVdPcBUiSJElav0E9BzV3CY3mSoYkSZKkogwZkiRJkooyZEiSJEkqypAhSZIkqShDhiRJkqSiDBmSJEmSijJkSJIkSSrKkCFJkiSpKEOGJEmSpKIMGZIkSZKKMmRIkiRJKsqQIUmSJLViEXFkREyPiBkRcdY6xhwXEVMjYkpE/HZ9c9aUL1OSJElSSxARbYHLgCOAucD4iBiVmVPrjRkAnA28PzMXR0SP9c3rSoYkSZLUeu0HzMjMmZn5BnADMHyNMV8ALsvMxQCZuWB9kxoyJEmSpNZrO2BOvfbcSl99OwE7RcRfI+LBiDhyfZP6uJQkSZK0iYqIkcDIel2XZ+blGzhNDTAAGAL0Au6LiPdk5pKGTpAkSZK0CaoEioZCxTygd712r0pffXOBv2fmMmBWRDxJXegYv65JfVxKkiRJar3GAwMion9EbAYcD4xaY8wt1K1iEBHdqHt8amZDkxoyJEmSpFYqM5cDpwJjgGnAjZk5JSLOj4hjKsPGAP+MiKnA3cCZmfnPhubdoMelIqIN0DEzX9zgO5AkSZL0jpOZo4HRa/SdU+91AqdXfhplvSsZEfHbiOgcER2Ax4GpEXFmo6uWJEmS1Ko05nGpgZWVi48AfwL6A5+ualWSJEmSWqzGhIx2EdGOupAxqrKrPKtbliRJkqSWqjEh41fAM0AH6j4Tty/gngxJkiRJa7Xejd+Z+VPgp/W6ZkfEodUrSZIkSVJL1piN31+tbPyOiLgqIh4GDmuC2iRJkiS1QI15XOrzlY3fHwC2pG7T98VVrUqSJElSi9WYkBGVf48Grs/MKfX6JEmSJGk1jQkZEyPiLupCxpiI6ATUVrcsSZIkSS1VY77x+yRgT2BmZr4SEVsDn6tuWZIkSZJaqsZ8ulRtRMwCdoqI9k1QkyRJkqQWbL0hIyJOBr4K9AImAQcAf8NPmJIkSZK0Fo3Zk/FVYF9gdmYeCrwXWFLVqiRJkiS1WI0JGa9l5msAEbF5Zj4B7FzdsiRJkiS1VI3Z+D03IroCtwD/FxGLgdnVLUuSJElSS9WYjd/HVl5+JyLuBroAd1a1KkmSJEkt1jpDRkRstZbuxyr/dgReqEpFkiRJklq0hlYyJgLJ6t/uvbKdwPZVrEuSJElSC7XOkJGZ/ZuyEEmSJEmbhnV+ulREDIuIj6+l/2MRcUR1y5IkSZLUUjX0EbbnAPeupf9e4PzqlCNJkiSppWsoZGyemQvX7MzMRUCH6pUkSZIkqSVrKGR0joi37NmIiHbAFtUrSZIkSVJL1tCnS90MXBERp2bmUoCI6Aj8pHKsqhZ+4y2LKJKk9Tj814c3dwmS1OJM2mFSc5ewyWkoZHwb+C4wOyJWfsN3H+Aq4L+qXZgkSZKkNw3qOai5S2i0hj7CdjlwVkScB+xY6Z6Rma82SWWSJEmSWqSGVjIAqISKx9Y3TpIkSZKg4Y3fkiRJkrTBDBmSJEmSilpvyIg6IyLinEq7T0TsV/3SJEmSJLVEjVnJ+DnwPuCESvsl4LKqVSRJkiSpRVvvxm9g/8zcKyIeAcjMxRGxWZXrkiRJktRCNWYlY1lEtAUSICK6A7VVrUqSJElSi9WYkPFT4I9Aj4i4EPgL8L2qViVJkiSpxWrM92T8JiImAkOBAD6SmdOqXpkkSZKkFmm9ISMi+gCvALfV78vMf1SzMEmSJEktU2M2ft9B3X6MANoD/YHpwG5VrEuSJElSC9WYx6XeU78dEXsB/161iiRJkiS1aBv8jd+Z+TCwfxVqkSRJkrQJaMyejNPrNdsAewHzq1aRJEmSpBatMXsyOtV7vZy6PRo3VaccSZIkSS1dgyGj8iV8nTLzjCaqR5IkSVILt849GRFRk5krgPc3YT2SJEmSWriGVjIeom7/xaSIGAX8AVi68mBm3lzl2iRJkiS1QI3Zk9Ee+CdwGG9+X0YChgxJkiRJb9FQyOhR+WSpx3kzXKyUVa1KkiRJUovVUMhoC3Rk9XCxkiFDkiRJ0lo1FDKezczzm6wSSZIkSZuEhr7xe20rGJIkSZLUoIZCxtAmq0KSJElSs4iIIyNiekTMiIizGhj3sYjIiNhnfXOuM2Rk5gsbW6gkSZKkd77Kl29fBhwFDAROiIiBaxnXCfgq8PfGzNvQSoYkSZKkTdt+wIzMnJmZbwA3AMPXMu4C4BLgtcZMasiQJEmSWq/tgDn12nMrfatExF5A78y8o7GTGjIkSZKkTVREjIyICfV+Rm7g+W2AHwLf2JDzGvON35IkSZJaoMy8HLi8gSHzgN712r0qfSt1AnYH7okIgHcDoyLimMycsK5JXcmQJEmSWq/xwICI6B8RmwHHA6NWHszMf2Vmt8zsl5n9gAeBBgMGGDIkSZKkViszlwOnAmOAacCNmTklIs6PiGM2dl4fl5IkSZJascwcDYxeo++cdYwd0pg5XcmQJEmSVJQhQ5IkSVJRhgxJkiRJRRkyJEmSJBVlyJAkSZJUlCFDkiRJUlGGDEmSJElFGTIkSZIkFWXIkCRJklSUIUOSJElSUYYMSZIkSUUZMiRJkiQVVdPcBUiSJElav0E9BzV3CY3mSoYkSZKkogwZkiRJkooyZEiSJEkqypAhSZIkqShDhiRJkqSiDBmSJEmSijJkSJIkSSrKkCFJkiSpKEOGJEmSpKIMGZIkSZKKMmRIkiRJKsqQIUmSJKkoQ4YkSZKkogwZkiRJkooyZEiSJEkqypAhSZIkqaia5i5Aam4PPvAgP770x9SuqOXDH/kwn/7cp1c7/sYbb3DBORcwfdp0unTpwvkXn882227D1MencsmFl9QNSvj8yM8z+LDBPP/c81xwzgUsfmExBAw/djjHfeq4ZrgzSaqeA3sfyDff/03aRBv+OO2PXDPpmtWOn3HgGey77b4AtK9pz1ZbbMXB1xwMwGVHX8YePffgkece4bQ/nbbqnHMHn8vA7gOJCGYvmc05d5/Dq8tfbbqbklSMIUOt2ooVK/jBxT/gxz//MT169uDkT5/MQYMPov/2/VeNuf2W2+nUuRM33nojY8eM5ec//TkXXHwB2++wPVddfxU1NTUsWriIz5zwGd5/yPtp27YtX/n6V9h5151ZunQpJ404iX0P2He1OSWpJWsTbTj7oLP50u1f4vmlz/Obj/6Ge2ffy8zFM1eNufSBS1e9Pn7349ml2y6r2v8z+X9oX9Oejw/8+GrzXvrApSxdthSAb7zvGxy/+/FvCS+SWgYfl1KrNm3KNHr17sV2vbajXbt2DP3AUO6/5/7Vxtx/7/0c/aGjARgydAgTH5pIZtJ+i/bU1NTl9DfeeIOIAKBb927svOvOAHTo0IG+/fuycMHCJrwrSaqu3XvszpwX5zDvpXksr13OmKfHMKTfkHWOP2rHo7hzxp2r2g/Ne4hXlr3ylnErAwbA5jWbk2TRuiU1HUOGWrWFCxbSo2ePVe0ePXuwcOHqgWDhwjfH1NTU0KFjB/615F8ATHlsCv/2iX/jxE+eyJlnn7kqdKz07PxneeqJp9ht992qfCeS1HR6dOjBcy8/t6r9/MvP06NDj7WO3abjNmzbaVsemvdQo+Y+b8h5jDtxHP279ueGx28oUq+kptfkISMiPtfU15SqZbf37MZv/vAbrrz+Sq6/9npef/31VcdeeeUVvnXmtzjtjNPo0LFDM1YpSc1n2I7DGDtzLLVZ26jx595zLkdcfwSzlsxi2A7DqlydpGppjpWM89Z1ICJGRsSEiJhw3dXXNWVNaqW69+jOgucXrGoveH4B3bt3X31M9zfHLF++nKUvL6VL1y6rjenXvx9bbLEFM5+uex55+bLlfOvMb/GBoz7AkMOGVPMWJKnJLVi6gHd3fPeqds+OPVmwdMFaxx6545GrPSrVGLVZy50z7mTo9kPfVp2Smk9VQkZEPLqOn8eAnus6LzMvz8x9MnOfEz9/YjVKk1azy8BdmDtnLvPnzWfZsmWMu2scBw0+aLUxBw0+iNG3jwbgnnH3sPe+exMRzJ83n+XLlwPw3LPPMfuZ2WyzzTZkJhddcBF9+/fl+BHHN/k9SVK1TVkwhT5d+rBtp22paVPDsB2Gce8z975lXL+u/ei8eWcmPz+5UfP27tx71evBfQcza/GsYjVLalrV+nSpnsAwYPEa/QE8UKVrShuspqaGr3/z65x+6umsWLGCDw3/ENvvsD1X/OIKdhm4CwcPPpgPDf8QF/zXBRw3/Dg6d+nMed+rW4x7dNKjXH/t9dTU1NAm2nDGWWfQdcuuTH5kMnfecSc77LgDnznhMwB88ctf5MCDDmzOW5WkYlbkCi7+y8X84oO/oE204dbpt/L04qc5ZZ9TmLpwKvfOrgsc61rFuHr41fTr2o93tXsXY0aM4Tv3fIcH5z7IBYddQId2HYgInvznk1x434VNfWuSConM8p/cEBFXAddk5l/Wcuy3mfmp9c2x6OVFfqSEJG2gw399eHOXIEktzqQvTYrmrqExxj09boPfHw/dYWiz3FtVVjIy86QGjq03YEiSJElqufwIW0mSJElFGTIkSZIkFWXIkCRJklSUIUOSJElSUYYMSZIkSUUZMiRJkiQVZciQJEmSVJQhQ5IkSVJRhgxJkiRJRRkyJEmSJBVlyJAkSZJasYg4MiKmR8SMiDhrLcdPj4ipEfFoRIyLiL7rm9OQIUmSJLVSEdEWuAw4ChgInBARA9cY9giwT2buAfwv8N/rm9eQIUmSJLVe+wEzMnNmZr4B3AAMrz8gM+/OzFcqzQeBXuub1JAhSZIktV7bAXPqtedW+tblJOBP65u05m0WJUmSJOkdKiJGAiPrdV2emZdv5FwjgH2Awesba8iQJEmSNlGVQNFQqJgH9K7X7lXpW01EHA58Cxicma+v77o+LiVJkiS1XuOBARHRPyI2A44HRtUfEBHvBX4FHJOZCxozqSFDkiRJaqUyczlwKjAGmAbcmJlTIuL8iDimMuz7QEfgDxExKSJGrWO6VXxcSpIkSWoBBvUcVJV5M3M0MHqNvnPqvT58Q+d0JUOSJElSUYYMSZIkSUUZMiRJkiQVZciQJEmSVJQhQ5IkSVJRhgxJkiRJRRkyJEmSJBVlyJAkSZJUlCFDkiRJUlGGDEmSJElFGTIkSZIkFWXIkCRJklSUIUOSJElSUYYMSZIkSUUZMiRJkiQVZciQJEmSVJQhQ5IkSVJRhgxJkiRJRRkyJEmSJBVlyJAkSZJUlCFDkiRJUlGGDEmSJElFGTIkSZIkFWXIkCRJklSUIUOSJElSUYYMSZIkSUUZMiRJkiQVZciQJEmSVJQhQ5IkSVJRhgxJkiRJRRkyJEmSJBVlyJAkSZJUlCFDkiRJUlGGDEmSJElFGTIkSZIkFWXIkCRJklSUIUOSJElSUYYMSZIkSUUZMiRJkiQVZciQJEmSVJQhQ5IkSVJRhgxJkiRJRRkyJEmSJBVlyJAkSZJUVGRmc9cgtTgRMTIzL2/uOiSppfDvptS6uJIhbZyRzV2AJLUw/t2UWhFDhiRJkqSiDBmSJEmSijJkSBvH54olacP4d1NqRdz4LUmSJKkoVzIkSZIkFWXIkDZARBwZEdMjYkZEnNXc9UjSO11EXB0RCyLi8eauRVLTMWRIjRQRbYHLgKOAgcAJETGweauSpHe8a4Ejm7sISU3LkCE13n7AjMycmZlvADcAw5u5Jkl6R8vM+4AXmrsOSU3LkCE13nbAnHrtuZU+SZIk1WPIkCRJklSUIUNqvHlA73rtXpU+SZIk1WPIkBpvPDAgIvpHxGbA8cCoZq5JkiTpHceQITVSZi4HTgXGANOAGzNzSvNWJUnvbBHxO+BvwM4RMTciTmrumiRVn9/4LUmSJKkoVzIkSZIkFWXIkCRJklSUIUOSJElSUYYMSZIkSUUZMiRJkiQVZciQpI0UEUHQkw8AAAPISURBVCsiYlJEPB4Rf4iId72Nua6NiI9XXl8ZEQMbGDskIg7ciGs8ExHd1tLfMSJ+FRFPR8TEiLgnIvavHHt5Q68jSZIhQ5I23quZuWdm7g68AXyp/sGIqNmYSTPz5Myc2sCQIcAGh4wGXAm8AAzIzL2BzwFvCSOSJDWWIUOSyrgf2LGyynB/RIwCpkZE24j4fkSMj4hHI+KLAFHnZxExPSLGAj1WTlRZSdin8vrIiHg4IiZHxLiI6EddmPl6ZRXl4IjoHhE3Va4xPiLeXzl364i4KyKmRMSVQKxZdETsAOwPfDszawEyc1Zm3rHGuI6V6z8cEY9FxPBKf4eIuKNS3+MR8clK/8URMbVyz5eW/VVLkt7pNup/2SRJb6qsWBwF3Fnp2gvYPTNnRcRI4F+ZuW9EbA78NSLuAt4L7AwMBHoCU4Gr15i3O3AFcEhlrq0y84WI+CXwcmZeWhn3W+BHmfmXiOhD3bfS7wqcC/wlM8+PiA8Ca/um5d2ASZm5Yj23+RpwbGa+WHnk6sFKkDoSmJ+ZH6zU0iUitgaOBXbJzIyIro37TUqSNhWGDEnaeFtExKTK6/uBq6h7jOmhzJxV6f8AsMfK/RZAF2AAcAjwu8qb+/kR8ee1zH8AcN/KuTLzhXXUcTgwMGLVQkXniOhYucZHK+feERGLN/I+oW4V5HsRcQhQC2xHXTh6DPhBRFwC3J6Z91dC12vAVRFxO3D727iuJKkFMmRI0sZ7NTP3rN9ReaO/tH4X8JXMHLPGuKML1tEGOCAzX1tLLeszBRgUEW3Xs5rxb0B3YO/MXBYRzwDtM/PJiNgLOBr4bkSMq6yc7AcMBT4OnAoctsF3JUlqsdyTIUnVNQY4JSLaAUTEThHRAbgP+GRlz8Y2wKFrOfdB4JCI6F85d6tK/0tAp3rj7gK+srIRESuDz33Apyp9RwFbrnmBzHwamACcF5VUEhH9Ko9X1dcFWFAJGIcCfStjtwVeycxfA98H9qqsonTJzNHA14FB6/slSZI2La5kSFJ1XQn0Ax6uvIlfCHwE+CN1/7s/FfgH8Lc1T8zMhZU9HTdHRBtgAXAEcBvwv5XN118BTgMui4hHqfu7fh91m8PPA34XEVOAByrXWZuTgR8AMyLiVWARcOYaY34D3BYRj1EXSp6o9L8H+H5E1ALLgFOoC0C3RkR76lZyTm/cr0qStKmIzGzuGiRJkiRtQnxcSpIkSVJRhgxJkiRJRRkyJEmSJBVlyJAkSZJUlCFDkiRJUlGGDEmSJElFGTIkSZIkFWXIkCRJklTU/weG6nMDKtQSZwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Note\n",
        "  * Please check the final.ipynb for the final test infetence"
      ],
      "metadata": {
        "id": "A6OJVeG6KWw0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# feature_name = pickle.load(open('/content/processors/feature_name.pkl','rb'))\n"
      ],
      "metadata": {
        "id": "rf7nBt9Em-48"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# feature_imp = { x[0]:x[1] for x in zip(feature_name,model.feature_importances_)}\n",
        "# pickle.dump(feature_imp,open(drive_path + '/feature_importance.pkl','wb'))\n",
        "\n",
        "# feature_imp_list = [ x for x in zip(feature_name,model.feature_importances_)]"
      ],
      "metadata": {
        "id": "XbugDCydnCzM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# feature_imp_list.sort(key=lambda x:x[1],reverse=True)\n"
      ],
      "metadata": {
        "id": "MbdWnTQ4nEY8"
      },
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vKn3KxYxnHas"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}